{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1\n",
    "\n",
    "### Assignment 1.1: Manual calculations\n",
    "\n",
    "Perform the following computation, and write the result below.\n",
    "\n",
    "![](images/conv_exe.png)\n",
    "\n",
    "1. Manually convolve the input, and compute the convolved features. No padding and stride of 1.\n",
    "       \n",
    "1. Perform `2x2` max pooling on the convolved features. Stride of 2.\n",
    "       \n",
    "\n",
    "**Answer:**\n",
    "   \n",
    "   [[8,7],[14,25]]\n",
    "   \n",
    "   25\n",
    "\n",
    "### Assignment 1.2: Output dimensionality\n",
    "\n",
    "Given the following 3D tensor input `(channel, height, width)` , a given amount (`channels_out`) of filters `(channels_in, filter_height, filter_width)`, stride `(height, width)` and padding `(height, width)`, calculate the output dimensionality if it's valid.\n",
    "\n",
    "1. input tensor with dimensionality (1, 28, 28) and 16 filters of size (1, 5, 5) with stride (1, 1) and padding (0, 0)\n",
    " * **Answer:** \n",
    " \n",
    " (28-5+1)^2x16 = 9216\n",
    "2. input tensor with dimensionality (3, 32, 32) and 24 filters of size (2, 3, 3) with stride (1, 1) and padding (0, 0)\n",
    " * **Answer:** \n",
    " \n",
    " (32-3+1)^2x3x24 = 64800\n",
    "3. input tensor with dimensionality (10, 32, 32) and 3 filters of size (10, 2, 2) with stride (2, 2) and padding (0, 0)\n",
    " * **Answer:** \n",
    " \n",
    " 3x10x16x16 = 7680\n",
    "4. input tensor with dimensionality (11, 8, 16) and 7 filters of size (11, 3, 3) with stride (2, 2) and padding (1, 1)\n",
    " * **Answer:** \n",
    " \n",
    " 7x11x4x8 = 2464\n",
    "5. input tensor with dimensionality (128, 256, 256) and 112 filters of size (128, 3, 3) with stride (1, 1) and padding (1, 1)\n",
    " * **Answer:** \n",
    " \n",
    " 112x128x256x256 = 939524096  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2\n",
    "\n",
    "1. Note the performance of the standard feedforward neural network. Add a 2D convolution layer before the dense hidden layer and confirm that it increases the generalization performance of the network (try num_filters=16 and filter_size=5 as a starting point). \n",
    " \n",
    "2. Notice that the size of the image reduces. This can cause loss of information in convolutional networks that apply many convolutional layers. To avoid such add adequate padding to the convolutional layer.\n",
    "\n",
    "<font color='red'>I tried to use different padding size in the convolutional layer, the performance slightly changed when padding size equal to 4, whereas when it is 1,2,3, the accuracy is almost identical to the one without padding, while with prize of compuing time.</font>\n",
    " \n",
    "3. Can the performance be increases even further by stacking more convolution layers ?\n",
    "\n",
    "<font color='red'> The performance is improved by 3%. Note that in orddr to speedup the computing, I set the paddding equal to zero, as the aim is to check if the accuracy is improved by adding another convolutional neural network. </font>\n",
    " \n",
    "4. Maxpooling is a technique for decreasing the spatial resolution of an image while retaining the important features. Effectively this gives a local translational invariance and reduces the computation by a factor of four. In the classification algorithm which is usually desirable. Try to either: \n",
    " \n",
    "   - add a maxpool layer (add arguement kernel_size=2, stride=2) after the convolution layer, or\n",
    "   - set add stride=2 to the arguments of the convolution layer, make it fit with the kernel size\n",
    "     \n",
    "  Verify that this decreases spatial dimension of the image (`print(l_conv_x.size())` or `print(l_maxpool_x.size())` in your forward pass). Does this increase the performance of the network (you may need to stack multiple layers or increase the number of filters to increase performance) ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.functional as F\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "channels, height, width = 1, 28, 28\n",
    "conv1_kernel_num = 16\n",
    "conv1_kernel_width = 5\n",
    "conv1_kernel_height = 5\n",
    "conv1_kernel_stride = 1\n",
    "conv1_pool_size = 2\n",
    "conv1_pool_stride = 2\n",
    "conv1_padding = 0\n",
    "\n",
    "conv2_kernel_num = 32\n",
    "conv2_kernel_width = 3\n",
    "conv2_kernel_height = 3\n",
    "conv2_kernel_stride = 1\n",
    "conv2_pool_size = 2\n",
    "conv2_pool_stride = 2\n",
    "conv2_padding = 0\n",
    "\n",
    "full_hidden_num1 = 100\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information on dataset\n",
      "x_train (1000, 1, 28, 28)\n",
      "targets_train (1000,)\n",
      "x_valid (500, 1, 28, 28)\n",
      "targets_valid (500,)\n",
      "x_test (500, 1, 28, 28)\n",
      "targets_test (500,)\n"
     ]
    }
   ],
   "source": [
    "data = np.load('mnist.npz')\n",
    "\n",
    "x_train = data['X_train'][:1000].astype('float32')\n",
    "x_train = x_train.reshape((-1, channels, height, width))\n",
    "targets_train = data['y_train'][:1000].astype('int32')\n",
    "\n",
    "x_valid = data['X_valid'][:500].astype('float32')\n",
    "x_valid = x_valid.reshape((-1, channels, height, width))\n",
    "targets_valid = data['y_valid'][:500].astype('int32')\n",
    "\n",
    "x_test = data['X_test'][:500].astype('float32')\n",
    "x_test = x_test.reshape((-1, channels, height, width))\n",
    "targets_test = data['y_test'][:500].astype('int32')\n",
    "\n",
    "print(\"Information on dataset\")\n",
    "print(\"x_train\", x_train.shape)\n",
    "print(\"targets_train\", targets_train.shape)\n",
    "print(\"x_valid\", x_valid.shape)\n",
    "print(\"targets_valid\", targets_valid.shape)\n",
    "print(\"x_test\", x_test.shape)\n",
    "print(\"targets_test\", targets_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "MyCnn(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), ceil_mode=False)\n",
      "  )\n",
      "  (fc1): Sequential(\n",
      "    (0): Linear(in_features=2304, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (out): Linear(in_features=100, out_features=10, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# with only one convolutional layer\n",
    "from torch.nn.functional import softmax\n",
    "class MyCnn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyCnn,self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Sequential(nn.Conv2d(in_channels=channels,out_channels=conv1_kernel_num,kernel_size=(conv1_kernel_width,conv1_kernel_height),stride =conv1_kernel_stride,padding=conv1_padding),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.MaxPool2d(kernel_size=conv1_pool_size,stride=conv1_pool_stride))\n",
    "        self.conv1_kernel_height = (height-conv1_kernel_height+2*conv1_padding)//conv1_kernel_stride+1\n",
    "        self.conv1_kernel_width = (width-conv1_kernel_width+2*conv1_padding)//conv1_kernel_stride +1\n",
    "        self.conv1_pool_height = (self.conv1_kernel_height-conv1_pool_size)//conv1_pool_stride+1\n",
    "        print(self.conv1_pool_height)\n",
    "        self.fc1_num_in = int(conv1_kernel_num*channels*(self.conv1_pool_height)**2)\n",
    "        self.fc1 = nn.Sequential(nn.Linear(in_features=self.fc1_num_in,out_features=full_hidden_num1),\n",
    "                                nn.ReLU())\n",
    "        self.out = nn.Linear(in_features=full_hidden_num1,out_features=num_classes,bias=False)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x)\n",
    "        x = x.view(-1,self.fc1_num_in)\n",
    "        #print(x.size())\n",
    "        x = self.fc1(x)\n",
    "        #x = self.out(x)\n",
    "        #print(type(x))\n",
    "        return softmax(self.out(x),dim=1)\n",
    "        \n",
    "        \n",
    "mycnn = MyCnn() \n",
    "print(mycnn)\n",
    "optimizer = optim.Adam(lr=0.01,params=mycnn.parameters())\n",
    "loss_function = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "batch_size = 100\n",
    "num_epochs = 50\n",
    "num_samples_train = x_train.shape[0]\n",
    "num_batches_train = num_samples_train // batch_size\n",
    "num_samples_valid = x_valid.shape[0]\n",
    "num_batches_valid = num_samples_valid // batch_size\n",
    "\n",
    "train_acc, train_loss = [], []\n",
    "valid_acc, valid_loss = [], []\n",
    "test_acc, test_loss = [], []\n",
    "cur_loss = 0\n",
    "losses = []\n",
    "\n",
    "get_slice = lambda i, size: range(i * size, (i + 1) * size)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward -> Backprob -> Update params\n",
    "    ## Train\n",
    "    cur_loss = 0\n",
    "    mycnn.train()\n",
    "    for i in range(num_batches_train):\n",
    "        slce = get_slice(i, batch_size)\n",
    "        x_batch = Variable(torch.from_numpy(x_train[slce]))\n",
    "        output = mycnn(x_batch)\n",
    "        \n",
    "        # compute gradients given loss\n",
    "        target_batch = Variable(torch.from_numpy(targets_train[slce]).long())\n",
    "        #print(type(output))\n",
    "        batch_loss = loss_function(output, target_batch)\n",
    "        optimizer.zero_grad()\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        cur_loss += batch_loss   \n",
    "    losses.append(cur_loss / batch_size)\n",
    "\n",
    "    mycnn.eval()\n",
    "    ### Evaluate training\n",
    "    train_preds, train_targs = [], []\n",
    "    for i in range(num_batches_train):\n",
    "        slce = get_slice(i, batch_size)\n",
    "        x_batch = Variable(torch.from_numpy(x_train[slce]))\n",
    "        \n",
    "        output = mycnn(x_batch)\n",
    "        preds = torch.max(output, 1)[1]\n",
    "        \n",
    "        train_targs += list(targets_train[slce])\n",
    "        train_preds += list(preds.data.numpy())\n",
    "    \n",
    "    ### Evaluate validation\n",
    "    val_preds, val_targs = [], []\n",
    "    for i in range(num_batches_valid):\n",
    "        slce = get_slice(i, batch_size)\n",
    "        x_batch = Variable(torch.from_numpy(x_valid[slce]))\n",
    "        \n",
    "        output = mycnn(x_batch)\n",
    "        preds = torch.max(output, 1)[1]\n",
    "        val_preds += list(preds.data.numpy())\n",
    "        val_targs += list(targets_valid[slce])\n",
    "\n",
    "    train_acc_cur = accuracy_score(train_targs, train_preds)\n",
    "    valid_acc_cur = accuracy_score(val_targs, val_preds)\n",
    "    \n",
    "    train_acc.append(train_acc_cur)\n",
    "    valid_acc.append(valid_acc_cur)\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(\"Epoch %2i : Train Loss %f , Train acc %f, Valid acc %f\" % (\n",
    "                epoch+1, losses[-1], train_acc_cur, valid_acc_cur))\n",
    "        \n",
    "epoch = np.arange(len(train_acc))\n",
    "plt.figure()\n",
    "plt.plot(epoch, train_acc, 'r', epoch, valid_acc, 'b')\n",
    "plt.legend(['Train Acc', 'Val Acc'])\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Acc')\n",
    "\n",
    "### Evaluate test set\n",
    "x_batch = Variable(torch.from_numpy(x_test))\n",
    "output = mycnn(x_batch)\n",
    "preds = torch.max(output, 1)[1]\n",
    "print(\"\\nTest set Acc:  %f\" % (accuracy_score(list(targets_test), list(preds.data.numpy()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyCnn2(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), ceil_mode=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), ceil_mode=False)\n",
      "  )\n",
      "  (fc1): Sequential(\n",
      "    (0): Linear(in_features=800, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (out): Linear(in_features=100, out_features=10, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# with two convolutional layers\n",
    "from torch.nn.functional import softmax\n",
    "class MyCnn2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyCnn2,self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Sequential(nn.Conv2d(in_channels=channels,out_channels=conv1_kernel_num,kernel_size=(conv1_kernel_width,conv1_kernel_height),stride =conv1_kernel_stride,padding=conv1_padding),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.MaxPool2d(kernel_size=conv1_pool_size,stride=conv1_pool_stride))\n",
    "        self.conv1_kernel_height = (height-conv1_kernel_height+2*conv1_padding)//conv1_kernel_stride+1\n",
    "        self.conv1_kernel_width = (width-conv1_kernel_width+2*conv1_padding)//conv1_kernel_stride +1\n",
    "        self.conv1_pool_height = (self.conv1_kernel_height-conv1_pool_size)//conv1_pool_stride+1\n",
    "        # as it is square, i don't want to specify conv1_pool_width\n",
    "     \n",
    "        self.conv2 = nn.Sequential(nn.Conv2d(in_channels=conv1_kernel_num,out_channels=conv2_kernel_num,kernel_size=(conv2_kernel_width,conv2_kernel_height),stride =conv2_kernel_stride,padding=conv2_padding),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.MaxPool2d(kernel_size=conv2_pool_size,stride=conv2_pool_stride))\n",
    "        self.conv2_kernel_height = (self.conv1_pool_height-conv2_kernel_height+2*conv2_padding)//conv2_kernel_stride+1\n",
    "        #print(self.conv1_pool_height)\n",
    "        self.conv2_kernel_width = (self.conv1_pool_height-conv2_kernel_width+2*conv2_padding)//conv2_kernel_stride +1\n",
    "        #print(self.conv2_kernel_height)\n",
    "        self.conv2_pool_height = (self.conv2_kernel_height-conv2_pool_size)//conv2_pool_stride+1\n",
    "        #print(self.conv2_pool_height)\n",
    "        \n",
    "        self.fc1_num_in = conv2_kernel_num*((self.conv2_pool_height)**2)\n",
    "        #print(self.fc1_num_in)\n",
    "        #self.fc1_num_in = int(conv1_kernel_num*channels*(self.conv1_pool_height)**2)\n",
    "        self.fc1 = nn.Sequential(nn.Linear(in_features=self.fc1_num_in,out_features=full_hidden_num1),\n",
    "                                nn.ReLU())\n",
    "        self.out = nn.Linear(in_features=full_hidden_num1,out_features=num_classes,bias=False)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x)\n",
    "        #print(\"----\",x.size())\n",
    "        x = self.conv2(x)\n",
    "        #print(\"....\",x.size())\n",
    "        x = x.view(-1,self.fc1_num_in)\n",
    "        #print(x.size())\n",
    "        x = self.fc1(x)\n",
    "        #x = self.out(x)\n",
    "        #print(type(x))\n",
    "        return softmax(self.out(x),dim=1)\n",
    "        \n",
    "        \n",
    "mycnn2 = MyCnn2() \n",
    "print(mycnn2)\n",
    "optimizer = optim.Adam(lr=0.01,params=mycnn2.parameters())\n",
    "loss_function = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1 : Train Loss 0.216950 , Train acc 0.555000, Valid acc 0.540000\n",
      "Epoch 11 : Train Loss 0.165859 , Train acc 0.805000, Valid acc 0.762000\n",
      "Epoch 21 : Train Loss 0.158189 , Train acc 0.893000, Valid acc 0.842000\n",
      "Epoch 31 : Train Loss 0.150341 , Train acc 0.970000, Valid acc 0.874000\n",
      "Epoch 41 : Train Loss 0.147826 , Train acc 0.984000, Valid acc 0.934000\n",
      "\n",
      "Test set Acc:  0.952000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "batch_size = 100\n",
    "num_epochs = 50\n",
    "num_samples_train = x_train.shape[0]\n",
    "num_batches_train = num_samples_train // batch_size\n",
    "num_samples_valid = x_valid.shape[0]\n",
    "num_batches_valid = num_samples_valid // batch_size\n",
    "\n",
    "train_acc, train_loss = [], []\n",
    "valid_acc, valid_loss = [], []\n",
    "test_acc, test_loss = [], []\n",
    "cur_loss = 0\n",
    "losses = []\n",
    "\n",
    "get_slice = lambda i, size: range(i * size, (i + 1) * size)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward -> Backprob -> Update params\n",
    "    ## Train\n",
    "    cur_loss = 0\n",
    "    mycnn2.train()\n",
    "    for i in range(num_batches_train):\n",
    "        slce = get_slice(i, batch_size)\n",
    "        \n",
    "        x_batch = Variable(torch.from_numpy(x_train[slce]))\n",
    "        #print(x_batch.size())\n",
    "        output = mycnn2(x_batch)\n",
    "        \n",
    "        # compute gradients given loss\n",
    "        target_batch = Variable(torch.from_numpy(targets_train[slce]).long())\n",
    "        #print(type(output))\n",
    "        batch_loss = loss_function(output, target_batch)\n",
    "        optimizer.zero_grad()\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        cur_loss += batch_loss   \n",
    "    losses.append(cur_loss / batch_size)\n",
    "\n",
    "    mycnn2.eval()\n",
    "    ### Evaluate training\n",
    "    train_preds, train_targs = [], []\n",
    "    for i in range(num_batches_train):\n",
    "        slce = get_slice(i, batch_size)\n",
    "        x_batch = Variable(torch.from_numpy(x_train[slce]))\n",
    "        \n",
    "        output = mycnn2(x_batch)\n",
    "        preds = torch.max(output, 1)[1]\n",
    "        \n",
    "        train_targs += list(targets_train[slce])\n",
    "        train_preds += list(preds.data.numpy())\n",
    "    \n",
    "    ### Evaluate validation\n",
    "    val_preds, val_targs = [], []\n",
    "    for i in range(num_batches_valid):\n",
    "        slce = get_slice(i, batch_size)\n",
    "        x_batch = Variable(torch.from_numpy(x_valid[slce]))\n",
    "        \n",
    "        output = mycnn2(x_batch)\n",
    "        preds = torch.max(output, 1)[1]\n",
    "        val_preds += list(preds.data.numpy())\n",
    "        val_targs += list(targets_valid[slce])\n",
    "\n",
    "    train_acc_cur = accuracy_score(train_targs, train_preds)\n",
    "    valid_acc_cur = accuracy_score(val_targs, val_preds)\n",
    "    \n",
    "    train_acc.append(train_acc_cur)\n",
    "    valid_acc.append(valid_acc_cur)\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(\"Epoch %2i : Train Loss %f , Train acc %f, Valid acc %f\" % (\n",
    "                epoch+1, losses[-1], train_acc_cur, valid_acc_cur))\n",
    "        \n",
    "epoch = np.arange(len(train_acc))\n",
    "plt.figure()\n",
    "plt.plot(epoch, train_acc, 'r', epoch, valid_acc, 'b')\n",
    "plt.legend(['Train Acc', 'Val Acc'])\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Acc')\n",
    "\n",
    "### Evaluate test set\n",
    "x_batch = Variable(torch.from_numpy(x_test))\n",
    "output = mycnn2(x_batch)\n",
    "preds = torch.max(output, 1)[1]\n",
    "print(\"\\nTest set Acc:  %f\" % (accuracy_score(list(targets_test), list(preds.data.numpy()))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3\n",
    "\n",
    "The visualized filters will likely look most like noise due to the small amount of training data.\n",
    "\n",
    "1. Try to use 10000 traning examples instead and visualise the filters again\n",
    " \n",
    "2. Dropout is a very usefull technique for preventing overfitting. Try to add a DropoutLayer after the convolution layer and hidden layer. This should increase both performance and the \"visual appeal\" of the filters\n",
    "   - remember to use `net.train()` and `net.eval()` properly.\n",
    " \n",
    "3. Batch normalization is a recent innovation for improving generalization performance. Try to insert batch normalization layers into the network to improve performance. \n",
    "   - remember to use `net.train()` and `net.eval()` properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information on dataset\n",
      "x_train (10000, 1, 28, 28)\n",
      "targets_train (10000,)\n",
      "x_valid (500, 1, 28, 28)\n",
      "targets_valid (500,)\n",
      "x_test (500, 1, 28, 28)\n",
      "targets_test (500,)\n"
     ]
    }
   ],
   "source": [
    "# increase the training dataset to 10000\n",
    "data = np.load('mnist.npz')\n",
    "\n",
    "x_train = data['X_train'][:10000].astype('float32')\n",
    "x_train = x_train.reshape((-1, channels, height, width))\n",
    "targets_train = data['y_train'][:10000].astype('int32')\n",
    "\n",
    "x_valid = data['X_valid'][:500].astype('float32')\n",
    "x_valid = x_valid.reshape((-1, channels, height, width))\n",
    "targets_valid = data['y_valid'][:500].astype('int32')\n",
    "\n",
    "x_test = data['X_test'][:500].astype('float32')\n",
    "x_test = x_test.reshape((-1, channels, height, width))\n",
    "targets_test = data['y_test'][:500].astype('int32')\n",
    "\n",
    "print(\"Information on dataset\")\n",
    "print(\"x_train\", x_train.shape)\n",
    "print(\"targets_train\", targets_train.shape)\n",
    "print(\"x_valid\", x_valid.shape)\n",
    "print(\"targets_valid\", targets_valid.shape)\n",
    "print(\"x_test\", x_test.shape)\n",
    "print(\"targets_test\", targets_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1 : Train Loss 1.919254 , Train acc 0.593400, Valid acc 0.572000\n",
      "Epoch 11 : Train Loss 1.483611 , Train acc 0.968300, Valid acc 0.956000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "batch_size = 100\n",
    "num_epochs = 50\n",
    "num_samples_train = x_train.shape[0]\n",
    "num_batches_train = num_samples_train // batch_size\n",
    "num_samples_valid = x_valid.shape[0]\n",
    "num_batches_valid = num_samples_valid // batch_size\n",
    "\n",
    "train_acc, train_loss = [], []\n",
    "valid_acc, valid_loss = [], []\n",
    "test_acc, test_loss = [], []\n",
    "cur_loss = 0\n",
    "losses = []\n",
    "\n",
    "get_slice = lambda i, size: range(i * size, (i + 1) * size)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward -> Backprob -> Update params\n",
    "    ## Train\n",
    "    cur_loss = 0\n",
    "    mycnn.train()\n",
    "    for i in range(num_batches_train):\n",
    "        slce = get_slice(i, batch_size)\n",
    "        x_batch = Variable(torch.from_numpy(x_train[slce]))\n",
    "        output = mycnn(x_batch)\n",
    "        \n",
    "        # compute gradients given loss\n",
    "        target_batch = Variable(torch.from_numpy(targets_train[slce]).long())\n",
    "        #print(type(output))\n",
    "        batch_loss = loss_function(output, target_batch)\n",
    "        optimizer.zero_grad()\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        cur_loss += batch_loss   \n",
    "    losses.append(cur_loss / batch_size)\n",
    "\n",
    "    mycnn.eval()\n",
    "    ### Evaluate training\n",
    "    train_preds, train_targs = [], []\n",
    "    for i in range(num_batches_train):\n",
    "        slce = get_slice(i, batch_size)\n",
    "        x_batch = Variable(torch.from_numpy(x_train[slce]))\n",
    "        \n",
    "        output = mycnn(x_batch)\n",
    "        preds = torch.max(output, 1)[1]\n",
    "        \n",
    "        train_targs += list(targets_train[slce])\n",
    "        train_preds += list(preds.data.numpy())\n",
    "    \n",
    "    ### Evaluate validation\n",
    "    val_preds, val_targs = [], []\n",
    "    for i in range(num_batches_valid):\n",
    "        slce = get_slice(i, batch_size)\n",
    "        x_batch = Variable(torch.from_numpy(x_valid[slce]))\n",
    "        \n",
    "        output = mycnn(x_batch)\n",
    "        preds = torch.max(output, 1)[1]\n",
    "        val_preds += list(preds.data.numpy())\n",
    "        val_targs += list(targets_valid[slce])\n",
    "\n",
    "    train_acc_cur = accuracy_score(train_targs, train_preds)\n",
    "    valid_acc_cur = accuracy_score(val_targs, val_preds)\n",
    "    \n",
    "    train_acc.append(train_acc_cur)\n",
    "    valid_acc.append(valid_acc_cur)\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(\"Epoch %2i : Train Loss %f , Train acc %f, Valid acc %f\" % (\n",
    "                epoch+1, losses[-1], train_acc_cur, valid_acc_cur))\n",
    "        \n",
    "epoch = np.arange(len(train_acc))\n",
    "plt.figure()\n",
    "plt.plot(epoch, train_acc, 'r', epoch, valid_acc, 'b')\n",
    "plt.legend(['Train Acc', 'Val Acc'])\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Acc')\n",
    "\n",
    "### Evaluate test set\n",
    "x_batch = Variable(torch.from_numpy(x_test))\n",
    "output = mycnn(x_batch)\n",
    "preds = torch.max(output, 1)[1]\n",
    "print(\"\\nTest set Acc:  %f\" % (accuracy_score(list(targets_test), list(preds.data.numpy()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to start with we print the names of the weights in our network\n",
    "names_and_vars = {x[0]: x[1] for x in cnnet.named_parameters()}\n",
    "print(names_and_vars.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ERROR - If you get a key error, then you need to define l_conv1 in your model!\n",
    "if not 'conv1.weight' in names_and_vars:\n",
    "    print(\"You need to go back and define a convolutional layer in the network.\")\n",
    "else:\n",
    "    np_W = names_and_vars['conv1.weight'].data.numpy() # get the filter values from the first conv layer\n",
    "    print(np_W.shape, \"i.e. the shape is (channels_out, channels_in, filter_height, filter_width)\")\n",
    "    channels_out, channels_in, filter_size, _ = np_W.shape\n",
    "    n = int(channels_out**0.5)\n",
    "\n",
    "    # reshaping the last dimension to be n by n\n",
    "    np_W_res = np_W.reshape(filter_size, filter_size, channels_in, n, n)\n",
    "    fig, ax = plt.subplots(n,n)\n",
    "    print(\"learned filter values\")\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            ax[i,j].imshow(np_W_res[:,:,0,i,j], cmap='gray',interpolation='none')\n",
    "            ax[i,j].xaxis.set_major_formatter(plt.NullFormatter())\n",
    "            ax[i,j].yaxis.set_major_formatter(plt.NullFormatter())\n",
    "\n",
    "    idx = 1\n",
    "    plt.figure()\n",
    "    plt.imshow(x_train[idx,0],cmap='gray',interpolation='none')\n",
    "    plt.title('Inut Image')\n",
    "    plt.show()\n",
    "\n",
    "    #visalize the filters convolved with an input image\n",
    "    from scipy.signal import convolve2d\n",
    "    np_W_res = np_W.reshape(filter_size, filter_size, channels_in, n, n)\n",
    "    fig, ax = plt.subplots(n,n,figsize=(9,9))\n",
    "    print(\"Response from input image convolved with the filters\")\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            ax[i,j].imshow(convolve2d(x_train[1,0],np_W_res[:,:,0,i,j],mode='same'),\n",
    "                           cmap='gray',interpolation='none')\n",
    "            ax[i,j].xaxis.set_major_formatter(plt.NullFormatter())\n",
    "            ax[i,j].yaxis.set_major_formatter(plt.NullFormatter())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
